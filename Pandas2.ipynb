{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjMd4xN0x6XkwWj88b48TE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dareoyeleke/python_scripting/blob/main/Pandas2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qU7zxxFN1NkZ"
      },
      "outputs": [],
      "source": [
        "! pip install datasets\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load data for use\n",
        "dataset = load_dataset('lukebarousse/data_jobs')\n",
        "df = dataset['train'].to_pandas()\n",
        "\n",
        "# Little bit of data clean up\n",
        "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We have a lot of NaN values in our DataFramee, and to clean the data to focus on only complete values, we can drop NaN values from our DataFrame\n",
        "\n",
        "df.iloc[0:10] # while we can use .iloc method, it strictly uses indexing to call certain ranges of rows and colums\n",
        "\n",
        "df.loc[0:, 'salary_rate':'salary_hour_avg'].dropna(subset='salary_rate')\n",
        "# .loc[] on the other hand allows filtering with column names, conditional filters, booleans e.t.c, the .dropna(subset=\"salary_rate\") allows to drop NaN values for salary_rate column"
      ],
      "metadata": {
        "id": "LTrq-xwM4lpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we will be filling in Nan values for yearly and hourly salaries with median as well as removing duplicate inputs of data in the dataframe. First we calculate the median values for the hourly and yearly salary\n",
        "median_yearly = df['salary_year_avg'].median()\n",
        "\n",
        "median_hourly = df['salary_hour_avg'].median()\n",
        "\n",
        "df_filled = df # to create a copy of the original dataframe to ensure original is not tampered with\n",
        "\n",
        "df_filled['salary_year_avg'].fillna(median_yearly) # to substitute the NaN values in salary_year_avg column with the median value\n",
        "\n",
        "df_filled['salary_hour_avg'].fillna(median_hourly) # to repeat the process for hourly NaN values\n",
        "\n",
        "# However both columns will not have median values filled in until replaced with the object carrying the filled values like  below\n",
        "df['salary_year_avg'] = df_filled['salary_year_avg'].fillna(median_yearly)\n",
        "\n",
        "df['salary_hour_avg'] = df_filled['salary_hour_avg'].fillna(median_hourly)\n",
        "\n",
        "df_filled # now we call the copy DataFrame and can see the NaN values have been filled"
      ],
      "metadata": {
        "id": "NQnwRn6Z5f5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now to eliminate the duplicate values in the DataFrame. First we create another copy to make it easier to backtrack in case of any errors\n",
        "df_dist = df_filled.copy()\n",
        "\n",
        "df_dist.drop_duplicates() # we still have store the results in the initial object\n",
        "df_dist = df_dist.drop_duplicates()\n",
        "\n",
        "# to view the difference before and after dropping the duplicates\n",
        "print(\"The number of rows before dropping duplicates were\", len(df_filled))\n",
        "print(\"The number of rows after dropping duplicates are now\", len(df_dist))\n",
        "print(\"The difference in number before and after dropping are\", len(df_filled) - len(df_dist)) # the results printed below show the numbers of rows, before, after and the difference of row numbers with .drop_duplicates()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgcxTCTg8rOc",
        "outputId": "ffef8909-0cec-49c1-86fb-d42dedd548bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of rows before dropping duplicates were 785741\n",
            "The number of rows after dropping duplicates are now 785640\n",
            "The difference in number before and after dropping are 101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# However we will be going even deeper on dropping duplicates, using the job_title and company name to remove any duplicates, first we create another duplicate in case of errors\n",
        "df_dist2 = df_dist.copy()\n",
        "df_dist2 = df_dist2.drop_duplicates(subset=['job_title', 'company_name'])\n",
        "# here we use a list passed as a subset in the drop_duplicates() method to get rid of duplicates in both columnms that may contain unique values generally applicable to the whole DataFrame\n",
        "\n",
        "print(\"The first set of unique rows after dropping general duplicates were\", len(df_dist))\n",
        "print(\"After filtering for extra duplicates zoning down on job title and company name the numbers are\", len(df_dist2))\n",
        "print(\"The difference in rows after removing the first and second sets of duplicates are\", len(df_dist) - len(df_dist2)) # the numbers before and after adding new columns to filter with and the difference is below\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYRC0jveAIBT",
        "outputId": "1a7fb540-01f9-41b3-9a80-798f4f63e175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first set of unique rows after dropping general duplicates were 785640\n",
            "After filtering for extra duplicates zoning down on job title and company name the numbers are 508042\n",
            "The difference in rows after removing the first and second sets of duplicates are 277598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  DataFrame managament. Here we will be using .sample(). The .sample() method is effective in getting a represetative portion of a DataFrame,\n",
        "which it does more effectively than the .head() and .tail() methods which print out a default first and last 5 rows of data. The .sample() returns random rows of data from a dataset\n",
        "with one row being the default, and a specified number of fraction of the total as an argument\n",
        "'''\n",
        "df.sample() # returns only one random row\n",
        "df.sample(10, random_state=42) # returns 10 random rows everytime it runs, to assign the sample, we can use inside the argument, \"random_state\" and assign it to a variable\n"
      ],
      "metadata": {
        "id": "Z3guwAEjEm-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we will be creating pivot tables to view the median salary by job title and Country for the countries with the 6 highest amounts of job postings using the index and aggfunc arguments in the .pivot_table() method\n"
      ],
      "metadata": {
        "id": "RKhSBFj8PC5w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}