{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp60nJCM0+Ket9uPjTlvsm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dareoyeleke/python_scripting/blob/main/Pandas3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dH3aQDksCGfQ"
      },
      "outputs": [],
      "source": [
        "! pip install datasets\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load data for use\n",
        "dataset = load_dataset('lukebarousse/data_jobs')\n",
        "df = dataset['train'].to_pandas()\n",
        "\n",
        "# Little bit of data clean up\n",
        "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'])\n",
        "\n",
        "# https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf. One stop shop cheat sheet as a reference for common Pandas information"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  I'll be showcasing merging DataFrames using a previously created pivot table showing the Number of Job Postings per month for every job position\n",
        "Once I get that done in this cell, I will be importing the DataFrame to be merged and then the real fun begins\n",
        "'''\n",
        "df_usa_jobs = df[df['job_country'] == \"United States\"]\n",
        "\n",
        "df_usa_jobs['job_month_posted'] = df_usa_jobs['job_posted_date'].dt.strftime('%B')\n",
        "# using the strftime function, we can print out the month from the job_posted_date from the df_usa_jobs DataFrame in a new column as the month names\n",
        "df_usa_jobs # Here we can check to confirm we have a column to prove the months were printed\n",
        "\n",
        "df_usa_month_pivot = df_usa_jobs.pivot_table(index='job_month_posted', columns='job_title_short', aggfunc='size')\n",
        "\n",
        "'''\n",
        "  This gives the number of job postings per month for every postion, taking NaN values also into consideration using 'size' as opposed to 'count' for the .aggfunc,\n",
        "however it prints out the months in alphabetical order as oppossed to chronologically, sorting can potentially change it to ascending or descending, but not chronological\n",
        "'''\n",
        "df_usa_month_pivot.reset_index(inplace=True) # We start by creating an index of numbers to attach the months to.\n",
        "\n",
        "df_usa_month_pivot['month_no'] = pd.to_datetime(df_usa_month_pivot['job_month_posted'], format='%B').dt.month  # creating a column aligning the month names with month numbers\n",
        "\n",
        "df_usa_month_pivot.sort_values('month_no', inplace=True) # sorting the month numbers, and thereby names in chronological order\n",
        "\n",
        "df_usa_month_pivot.set_index('job_month_posted', inplace=True) # and then setting the month numbers, month_no as the index.\n",
        "\n",
        "df_usa_month_pivot.drop(columns='month_no', inplace=True)\n",
        "# df_usa_month_pivot.drop(columns=['level_0', 'index', inplace=True]) used to drop recurring columns specified in list, columns\n",
        "\n",
        "df_usa_month_pivot # now we have our final table cleaned up for plotting\n",
        "\n",
        "data_jobs = ['Data Analyst', 'Data Engineer', 'Data Scientist'] # To narrow down to only the Data jobs I'm concerned about\n",
        "\n",
        "Data_job_month_demand = df_usa_month_pivot[data_jobs]\n",
        "\n",
        "Data_job_month_demand # However in the next cell I will be working with all the jobs in the table, not just Data jobs, so I will be using the DataFrame before filtering for Data Jobs, i.e df_usa_month_pivot\n",
        "\n",
        "\n",
        "df_usa_month_pivot # This is the DataFrame I will be merging the Software DataFrame with, how\n"
      ],
      "metadata": {
        "id": "qNicNW_CXc7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "software_jobs = pd.read_csv(\"https://lukeb.co/software_csv\") # Importing and creating a DataFrame for software jobs from the internet\n",
        "\n",
        "software_jobs = software_jobs.set_index('job_posted_month')  # Here we set the index to The month column\n",
        "\n",
        "software_jobs_DF = software_jobs.copy() # Create a copy so the original remains intact\n",
        "\n",
        "software_jobs_DF\n",
        "\n",
        "software_jobs_DF.rename(columns={'Front-End Developer' : 'Front_End_Dev', 'Back-End Developer' : 'Back_End_Dev', 'Full-Stack Developer' : 'Full_Stack_Dev', 'UI/UX Designer' : 'UI/UX_Des' })\n",
        "# rename the columns to make them easier to call\n",
        "\n",
        "# However to make merging easier, I'll make sure the identical columns have identical column names\n",
        "df_usa_month_pivot.index.name = 'job_posted_month'\n",
        "df_usa_month_pivot.index.name\n",
        "# since it is the index, I have to use the .index.name as opposed to .rename(column) to change the name, alternatively I could use left_on, and right_on to merge columns with different names\n",
        "\n",
        "# Now to merge both DataFrames\n",
        "\n",
        "df_US_merged_jobs = df_usa_month_pivot.merge(software_jobs_DF, on='job_posted_month')"
      ],
      "metadata": {
        "id": "RUIkRAq5DGRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  I will be creating another visual showing the top 5 Jobs from the merged Table to see the Trends in Jobs over the course of the year.\n",
        "To get the top 5 jobs, we'll be doing a sum of the job counts to see the top 5 first, and then plotting those 5 jobs\n",
        "'''\n",
        "\n",
        "top_5_jobs = (df_US_merged_jobs\n",
        "              .sum() # sum of all job positios\n",
        "              .sort_values(ascending=False) # sort the sums from ascending to descending\n",
        "              .head() # gives the top 5 values\n",
        "              .index) # prints out the index values\n",
        "\n",
        "top_5_jobs # The names of the top 5 jobs we need for the visual\n",
        "\n",
        "df_US_merged_jobs[top_5_jobs].plot() # plots a line chart by default\n",
        "plt.title('Job Postings Per Month for Top Tech Jobs for 2023')\n",
        "plt.ylabel('No of Job Postings')\n",
        "plt.xlabel('Year 2023')\n",
        "plt.xticks(rotation= 45)\n",
        "plt.legend(title='Job Title')\n",
        "plt.ylim(0, 25000)\n",
        "plt.show()\n",
        "\n",
        "# We now have a line chart showing the Trends in Job Postings for year 2023\n"
      ],
      "metadata": {
        "id": "Gl4KjMr0aCD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  Next using Concatenate method, I will be creating a DataFrame, to represent the Data for the first yearly quater, i.e Jan - March.\n",
        "Concatenate, as opposed to Merge( adding more columns to the DataFrames), Bascially adds more rows. I.e Merge is sideways increasing,\n",
        "concatenate is lengthwise increasing. To do that, I'll be creating some DataFrames by segmenting data from DataFrame(df) by the month and then concatenating them.\n",
        "'''\n",
        "df['job_posted_month'] = df['job_posted_date'].dt.strftime('%b') # first i create a new column pulling out shortened month names from the date/time column\n",
        "\n",
        "months = df['job_posted_month'].unique() # and then put those values in a list and store them in an object\n",
        "\n",
        "months\n",
        "\n",
        "dict_months = {month : df[df['job_posted_month'] == month] for month in months }\n",
        "'''\n",
        "  I use dict comprehension for every value in the object month printed out with the key as the month, and the value as a DataFrame printed out,\n",
        "filtering the DataFrame(df) for the month called through every iteration of the loop. i.e if the month is Jan, filter df where the\n",
        "'job_posted_month' is also Jan and store the key value as Jan, repeat this for every month value in months(holds all the month values)\n",
        "'''\n",
        "\n",
        "dict_months['Jan'] # verifying that it works by checking for the month of Jan\n",
        "\n",
        "# Now to finally concat the data\n",
        "df_Q1 = pd.concat([dict_month['Jan'], dict_month['Feb'], dict_month['Mar']], ignore_index=True) # Here we have the Job Postings for Q1 in order from Jan to March\n",
        "df_Q1"
      ],
      "metadata": {
        "id": "lZG-BcwDhXbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  Exporting Data to different formats using the .to_() to other data formats like csv, Excel and even sql if needed\n",
        "'''\n",
        "df_Q1.to_csv(' Quater_1.csv', index=False)\n",
        "#saving it as a csv file, with the .csv extension allows it to properly format as a csv file, keeping the index False allows the csv file to create its own index, preventing multiple indxes from automatically existing.\n"
      ],
      "metadata": {
        "id": "WrtV94rI1Hgi"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n7Q35D0L74AR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}